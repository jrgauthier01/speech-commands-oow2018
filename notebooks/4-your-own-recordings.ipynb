{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Optional) Testing the Function Endpoint with your Own Audio Clips\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using pre-recorded clips we show you in this notebook how to invoke the deployed Function \n",
    "with your **own** audio clips. \n",
    "\n",
    "In the cells below, we will use the [PyAudio library](https://pypi.org/project/PyAudio/) to record a short 1 second clip. we will then submit \n",
    "that short clip to the Function endpoint on Oracle Functions. **Make sure PyAudio is installed on your laptop** before running this notebook. \n",
    "\n",
    "The helper function defined below will record a 1-sec audio clip when executed. Speak into the microphone \n",
    "of your computer and say one of the words `cat`, `eight`, `right`. \n",
    "\n",
    "I'd recommend double-checking that you are not muted and that you are using the internal computer mic. No \n",
    "headset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will use pyaudio and wave in the \n",
    "# bottom half of this notebook. \n",
    "import pyaudio\n",
    "import wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pyaudio.__version__) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_wave(duration=1.0, output_wave='./output.wav'): \n",
    "    \"\"\"Using the pyaudio library, this function will record a video clip of a given duration. \n",
    "    \n",
    "    Args: \n",
    "        - duration (float): duration of the recording in seconds \n",
    "        - output_wave (str) : filename of the wav file that contains your recording \n",
    "        \n",
    "    Returns: \n",
    "        - frames : a list containing the recorded waveform\n",
    "    \"\"\"\n",
    "    \n",
    "    # number of frames per buffer\n",
    "    frames_perbuff = 2048 \n",
    "    # 16 bit int\n",
    "    format = pyaudio.paInt16\n",
    "    # mono sound\n",
    "    channels = 1 \n",
    "    # Sampling rate -- CD quality (44.1 kHz). Standard \n",
    "    # for most recording devices. \n",
    "    sampling_rate = 44100 \n",
    "    # frames contain the waveform data: \n",
    "    frames = []\n",
    "    # number of buffer chunks: \n",
    "    nchunks = int(duration * sampling_rate / frames_perbuff)\n",
    "\n",
    "    p = pyaudio.PyAudio()\n",
    "\n",
    "    stream = p.open(format=format,\n",
    "                channels=channels,\n",
    "                rate=sampling_rate,\n",
    "                input=True,\n",
    "                frames_per_buffer=frames_perbuff) \n",
    "    \n",
    "    print(\"RECORDING STARTED \")\n",
    "    for i in range(0, nchunks):\n",
    "        data = stream.read(frames_perbuff)\n",
    "        frames.append(data)\n",
    "    print(\"RECORDING ENDED\")\n",
    "    \n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()\n",
    "    \n",
    "    # Write the audio clip to disk as a .wav file: \n",
    "    wf = wave.open(output_wave, 'wb')\n",
    "    wf.setnchannels(channels)\n",
    "    wf.setsampwidth(p.get_sample_size(format))\n",
    "    wf.setframerate(sampling_rate)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's record your own, 1-sec clip\n",
    "my_own_clip = \"./my_clip.wav\"\n",
    "frames = record_wave(output_wave=my_own_clip)\n",
    "\n",
    "# Playback \n",
    "ipd.Audio(\"./my_clip.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good? Now let's try to send that clip to our model API endpoint. We will repeat the same process we adopted when we submitted pre-recorded clips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oci: \n",
    "import oci \n",
    "from oci.config import from_file\n",
    "from oci import pagination\n",
    "import oci.functions as functions\n",
    "from oci.functions import FunctionsManagementClient, FunctionsInvokeClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets specify the location of our OCI configuration file: \n",
    "oci_config = from_file(\"/home/datascience/block_storage/.oci/config\")\n",
    "\n",
    "# Lets specify the compartment OCID, and the application + function names: \n",
    "compartment_id = 'ocid1.compartment.oc1..aaaaaaaafl3avkal72rrwuy4m5rumpwh7r4axejjwq5hvwjy4h4uoyi7kzyq' \n",
    "app_name = 'machine-learning-models'\n",
    "fn_name = 'speech-commands'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_management_client = FunctionsManagementClient(oci_config)\n",
    "\n",
    "app_result = pagination.list_call_get_all_results(\n",
    "        fn_management_client.list_applications,\n",
    "        compartment_id,\n",
    "        display_name=app_name\n",
    "    )\n",
    "\n",
    "fn_result = pagination.list_call_get_all_results(\n",
    "        fn_management_client.list_functions,\n",
    "        app_result.data[0].id,\n",
    "        display_name=fn_name\n",
    "    )\n",
    "\n",
    "invoke_client = FunctionsInvokeClient(oci_config, service_endpoint=fn_result.data[0].invoke_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we need to be careful. `my_own_clip` was recorded at a 44.1 kHz sampling rate. \n",
    "# Yet the training sample has data at a 16 kHz rate. To ensure that we feed data of the same \n",
    "# size, we will downsample the data to a 16 kHz rate (sr=16000)\n",
    "waveform, _ = librosa.load(my_own_clip, mono=True, sr=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we call the deployed Function. Note that the first call could take 60 sec. or more. This is due to the cold start problem of Function. Subsequent calls are much faster. Typically < 1 sec. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "resp = invoke_client.invoke_function(fn_result.data[0].id, \n",
    "                                     invoke_function_body=json.dumps({\"input\": waveform.tolist()}))\n",
    "print(resp.data.text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
